<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model Pretraining</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <style>
    .gallery {
      width: 100%;
      max-width: 900px; /* 可以根据需要调整 */
      margin: 0 auto;
    }

    .row {
        display: flex;
        justify-content: space-between;
        margin-bottom: 5px; /* 行间距 */
    }

    .row img {
        width: 19.5%; /* 略小于 25% 以留出间距 */
        height: auto;
    }
</style>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model Pretraining</h1>
          <div class="is-size-5 publication-authors">
            <!-- Paper authors -->
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=IOiro9MAAAAJ&hl=zh-CN" target="_blank">Jie Cheng</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              Ruixi Qiao<sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=F4ypDHIAAAAJ" target="_blank">Gang Xiong</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=Q4B36ucAAAAJ" target="_blank">Qinghai Miao</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=ygjCiRAAAAAJ" target="_blank">Yingwei Ma</a><sup>3</sup>,
            </span>
            <span class="author-block">
              Binhua Li<sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=xF5VrokAAAAJ" target="_blank">Yongbin Li</a><sup>3*</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=RRKqjKAAAAAJ" target="_blank">Yisheng Lv</a><sup>3*</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <sup>1</sup>State Key Laboratory of Multimodal Artificial Intelligence Systems, CASIA<br>
              <sup>2</sup>Artificial Intelligence, University of Chinese Academy of Sciences<br>
              <sup>3</sup>Alibaba Group
            </span>
            <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Authors</small></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Arxiv PDF link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.00564" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Paper</span>
                </a>
              </span>

              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/CJReinforce/JOWA" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <h2 class="subtitle has-text-centered">
    <b>TL;DR:</b> A single JOWA-150M agent masters 15 Atari games at 84.7% human-level <br>
    and 119.5% DQN-level, and can adapt to novel games with ~4 expert demos. 
  </h2>
  <div class="gallery">
    <div class="row">
      <img src="static/images/Assault.gif" alt="Assault">
      <img src="static/images/Atlantis.gif" alt="Atlantis">
      <img src="static/images/Carnival.gif" alt="Carnival">
      <img src="static/images/ChopperCommand.gif" alt="ChopperCommand">
      <img src="static/images/DemonAttack.gif" alt="DemonAttack">
    </div>
    <div class="row">
      <img src="static/images/NameThisGame.gif" alt="NameThisGame">
      <img src="static/images/Seaquest.gif" alt="Seaquest">
      <img src="static/images/SpaceInvaders.gif" alt="SpaceInvaders">
      <img src="static/images/TimePilot.gif" alt="TimePilot">
      <img src="static/images/Zaxxon.gif" alt="Zaxxon">
    </div>
    <p class="note">
      Note: Training used 84x84 grayscale images. RGB demos shown here for better visualization. 
      For Atlantis, only the first 7 minutes of the 2-hour gameplay are displayed.
    </p><br>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            A significant aspiration of offline reinforcement learning (RL) is to develop a generalist agent with high capabilities from large and heterogeneous datasets. However, prior approaches that scale offline RL either rely heavily on expert trajectories or struggle to generalize to diverse unseen tasks. Inspired by the excellent generalization of world model in conditional video generation, we explore the potential of image observation-based world model for scaling offline RL and enhancing generalization on novel tasks. In this paper, we introduce JOWA: Jointly-Optimized World-Action model, an offline model-based RL agent pretrained on multiple Atari games with 6 billion tokens data to learn general-purpose representation and decision-making ability. Our method jointly optimizes a world-action model through a shared transformer backbone, which stabilize temporal difference learning with large models during pretraining. Moreover, we propose a provably efficient and parallelizable planning algorithm to compensate for the Q-value estimation error and thus search out better policies. Experimental results indicate that our largest agent, with 150 million parameters, achieves 78.9% human-level performance on pretrained games using only 10% subsampled offline data, outperforming existing state-of-the-art large-scale offline RL baselines by 31.6% on averange. Furthermore, JOWA scales favorably with model capacity and can sample-efficiently transfer to novel games using only 5k offline fine-tuning data (approximately 4 trajectories) per game, demonstrating superior generalization.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{cheng2024scaling,
    title={Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model Pretraining},
    author={Cheng, Jie and Qiao, Ruixi and Xiong, Gang and Miao, Qinghai and Ma, Yingwei and Li, Binhua and Li, Yongbin and Lv, Yisheng},
    journal={arXiv preprint arXiv:2410.00564},
    year={2024}
}</code></pre>
  </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

</body>
</html>
